{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext dotenv\n",
    "%dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get raw data from GCP bucket\n",
    "import sys\n",
    "import numpy as np\n",
    "np.set_printoptions(threshold=1000)\n",
    "\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "from PIL import Image\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import json\n",
    "import tempfile\n",
    "from datetime import datetime\n",
    "\n",
    "from google.cloud import storage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 50)\n",
    "pd.set_option('display.width', 100)\n",
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The bucket name for the location of the data is in the .env file\n",
    "BUCKET_NAME = os.environ['BUCKET_NAME']\n",
    "JSON_FILE = 'all_json_new.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Preprocesser:\n",
    "    def __init__(self):\n",
    "        self.keywords = [\n",
    "            'nonpharmaceutical intervention',\n",
    "            'handwashing',\n",
    "            'wipe down',\n",
    "            'public health',\n",
    "            'social behavior',\n",
    "            'community spread',\n",
    "            'containment',\n",
    "            'business closures',\n",
    "            'basic reproduction number',\n",
    "            'infection attack rate',\n",
    "            'lockdown',\n",
    "            'disease natural history',\n",
    "            'incident command system',\n",
    "            'emergency operations',\n",
    "            'joint information center',\n",
    "            'social distancing',\n",
    "            'childcare closers',\n",
    "            'travel advisory',\n",
    "            'travel warning',\n",
    "            'isolation',\n",
    "            'quarantine',\n",
    "            'mass gathering cancellations',\n",
    "            'school closures',\n",
    "            'facility closures',\n",
    "            'evacuation',\n",
    "            'relocation',\n",
    "            'restricing travel',\n",
    "            'travel ban',\n",
    "            'patient cohort',\n",
    "            'npi']\n",
    "        self.occurances_minimum = 4\n",
    "        storage_client = storage.Client()\n",
    "        temp = tempfile.TemporaryFile()\n",
    "        storage_client.download_blob_to_file(f\"gs://{BUCKET_NAME}/{JSON_FILE}\", temp)\n",
    "        self.df_full = pd.read_pickle(temp, compression=None)\n",
    "        print(self.df_full.shape)\n",
    "        self.key_slice()\n",
    "        print(self.df_full.shape)\n",
    "        self.npi_slice()\n",
    "        print(self.df_full.shape)\n",
    "    \n",
    "    def key_slice(self):\n",
    "        self.df_full = self.df_full[self.df_full['body_text'].str.contains('|'.join(self.keywords), na=False, regex=True)].reset_index()\n",
    "        \n",
    "    def npi_slice(self):\n",
    "        def get_count(row):\n",
    "            return sum([row['body_text'].count(keyword) for keyword in self.keywords])\n",
    "        self.df_full = self.df_full[self.df_full.apply(get_count, axis=1) > self.occurances_minimum]\n",
    "        \n",
    "    def remove_stopwords(self,columns):\n",
    "        stop = stopwords.words('english')\n",
    "        for col in columns:\n",
    "            self.df_full[col] = self.df_full[col].astype(str).apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))\n",
    "\n",
    "    def to_tfidf(self,columns):\n",
    "        for col in columns:\n",
    "            tfidfv = TfidfVectorizer()\n",
    "            self.df_full[col + '_tfidf'] = list(tfidfv.fit_transform(self.df_full[col]).toarray())\n",
    "            \n",
    "    def remove_punc(self, columns):\n",
    "        for col in columns:\n",
    "            self.df_full[col] = self.df_full[col].str.replace('[^a-zA-Z\\s]+','')\n",
    "        \n",
    "def display_wordcloud(text):\n",
    "    wordcloud = WordCloud(max_font_size=50, max_words=100, background_color='white').generate(text)\n",
    "    plt.figure()\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pca_apply(df, columns, n_comp):\n",
    "    new_df = df.copy()\n",
    "    for col in columns:\n",
    "        pca = PCA(n_components=n_comp)\n",
    "        new_df[col+'_pca'] = list(pca.fit_transform(np.stack(df[col].to_numpy())))\n",
    "    return new_df\n",
    "\n",
    "def apply_scaler(df, columns):\n",
    "    new_df = df.copy()\n",
    "    for col in columns:\n",
    "        scaler = StandardScaler()\n",
    "        new_df[col + '_scaled'] = list(scaler.fit_transform(np.stack(df[col].to_numpy())))\n",
    "    return new_df\n",
    "\n",
    "def cluster(df, columns, clust_nums):\n",
    "    new_df = df.copy()\n",
    "    for col in columns:\n",
    "        kmeans = KMeans(n_clusters = clust_nums)\n",
    "        new_df[col + \"_clusterID\"] = list(kmeans.fit_predict(np.stack(df[col].to_numpy())))\n",
    "    return new_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3851, 8)\n",
      "(3851, 9)\n",
      "(1157, 9)\n"
     ]
    }
   ],
   "source": [
    "prepr = Preprocesser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepr.remove_punc(['body_text','abstract'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepr.remove_stopwords(['body_text', 'abstract'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepr.to_tfidf(['body_text', 'abstract'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_df = pca_apply(prepr.df_full, ['abstract_tfidf','body_text_tfidf'], 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_df = apply_scaler(pca_df,['abstract_tfidf_pca','body_text_tfidf_pca'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustered_df = cluster(scaled_df, ['abstract_tfidf_pca_scaled', 'body_text_tfidf_pca_scaled'], 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    760\n",
       "5    147\n",
       "0    54 \n",
       "9    44 \n",
       "8    40 \n",
       "4    37 \n",
       "3    30 \n",
       "7    19 \n",
       "2    14 \n",
       "6    12 \n",
       "Name: body_text_tfidf_pca_scaled_clusterID, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clustered_df.body_text_tfidf_pca_scaled_clusterID.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>445</td>\n",
       "      <td>lack of cross-protection against mycoplasma haemofelis infection and signs of enhancement in \"candidatus mycoplasma turicensis\"-recovered cats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>518</td>\n",
       "      <td>isolation and identification of feline herpesvirus type 1 from a south china tiger in china</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>623</td>\n",
       "      <td>environmental contamination and hygienic measures after feline calicivirus field strain infections of cats in a research facility</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>870</td>\n",
       "      <td>feline calicivirus and other respiratory pathogens in cats with feline calicivirus- related symptoms and in clinically healthy cats in switzerland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1415</td>\n",
       "      <td>co-infection with feline retrovirus is related to changes in immunological parameters of cats with sporotrichosis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2022</td>\n",
       "      <td>infectious disease prevalence and factors associated with upper respiratory infection in cats following relocation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2173</td>\n",
       "      <td>stimulation with a class a cpg oligonucleotide enhances resistance to infection with feline viruses from five different families</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2211</td>\n",
       "      <td>reversal of the progression of fatal coronavirus infection in cats by a broad- spectrum coronavirus protease inhibitor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2706</td>\n",
       "      <td>retroviral dna-the silent winner: blood transfusion containing latent feline leukemia provirus causes infection and disease in naïve recipient cats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2803</td>\n",
       "      <td>highly suspected cases of salmonellosis in two cats fed with a commercial raw meat- based diet: health risks to animals and zoonotic implications</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3033</td>\n",
       "      <td>isolation and identification of feline calicivirus and feline herpesvirus in southern brazil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3589</td>\n",
       "      <td>exposure of cats to low doses of felv: seroconversion as the sole parameter of infection</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                    title\n",
       "445   lack of cross-protection against mycoplasma haemofelis infection and signs of enhancement in \"candidatus mycoplasma turicensis\"-recovered cats     \n",
       "518   isolation and identification of feline herpesvirus type 1 from a south china tiger in china                                                        \n",
       "623   environmental contamination and hygienic measures after feline calicivirus field strain infections of cats in a research facility                  \n",
       "870   feline calicivirus and other respiratory pathogens in cats with feline calicivirus- related symptoms and in clinically healthy cats in switzerland \n",
       "1415  co-infection with feline retrovirus is related to changes in immunological parameters of cats with sporotrichosis                                  \n",
       "2022  infectious disease prevalence and factors associated with upper respiratory infection in cats following relocation                                 \n",
       "2173  stimulation with a class a cpg oligonucleotide enhances resistance to infection with feline viruses from five different families                   \n",
       "2211  reversal of the progression of fatal coronavirus infection in cats by a broad- spectrum coronavirus protease inhibitor                             \n",
       "2706  retroviral dna-the silent winner: blood transfusion containing latent feline leukemia provirus causes infection and disease in naïve recipient cats\n",
       "2803  highly suspected cases of salmonellosis in two cats fed with a commercial raw meat- based diet: health risks to animals and zoonotic implications  \n",
       "3033  isolation and identification of feline calicivirus and feline herpesvirus in southern brazil                                                       \n",
       "3589  exposure of cats to low doses of felv: seroconversion as the sole parameter of infection                                                           "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clustered_df[clustered_df.body_text_tfidf_pca_scaled_clusterID == 6][['title']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1157"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(prepr.df_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "## authors do not seem to be repeating within their clusters\n",
    "# print(len(meta_arr[4]['cluster']))\n",
    "# meta_arr[4]['cluster'].author_list.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/bvs002/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from collections import Counter\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Explore Clusters\n",
    "class Explore_Cluster:\n",
    "    def __init__(self, clusetered_df):\n",
    "        self.clustered_df = clustered_df\n",
    "        self.cluster_count = len(clustered_df.body_text_tfidf_pca_scaled_clusterID.value_counts())\n",
    "        self.clusters = [pd.DataFrame([row[1] for row in clustered_df.iterrows() if row[1].body_text_tfidf_pca_scaled_clusterID == i]) for i in range (self.cluster_count)]\n",
    "        self.meta_arr = [{ 'size': len(cluster_df), 'cluster': cluster_df } for cluster_df in self.clusters]\n",
    "        self.top_limit = 30\n",
    "        self.top_title_tokens = self.get_top_title_tokens()\n",
    "        \n",
    "        for meta in self.meta_arr:\n",
    "            meta['keywords'] = [word for word in self.tokenize_and_clean(meta['cluster'].title) if word not in self.top_title_tokens]\n",
    "            meta['keywords'] = [value[0] for value in Counter(meta['keywords']).most_common()[0:5]]\n",
    "            \n",
    "        \n",
    "    def get_top_title_tokens(self):\n",
    "        all_title_tokens = []\n",
    "        for meta in self.meta_arr:\n",
    "            all_title_tokens.extend(self.tokenize_and_clean(meta['cluster'].title))\n",
    "        return [value[0] for value in Counter(all_title_tokens).most_common()[0:self.top_limit]]\n",
    "        \n",
    "    def tokenize_and_clean(self, titles):\n",
    "        title_tokens = []\n",
    "        for title in titles:\n",
    "            title = re.sub('(/|\\|:|&|#|-|\\.)', '', title)\n",
    "            tokens = word_tokenize(title)\n",
    "            remove_sw = [word for word in tokens if word not in stopwords.words('english')]\n",
    "            remove_numbers = [word for word in remove_sw if not word.isnumeric()]\n",
    "            remove_comas = [word for word in remove_numbers if not word in [',', '(', ')', '\"', ':', '``', '.', '?']]\n",
    "            title_tokens.extend(remove_comas)\n",
    "        return title_tokens    \n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "ec = Explore_Cluster(clustered_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2019ncov', 'cases', 'title', 'based', 'interval']\n",
      "-------------------------\n",
      "['middle', 'east', 'detection', 'patients', 'acute']\n",
      "-------------------------\n",
      "['porcine', 'diarrhea', 'isolation', 'swine', 'spraydried']\n",
      "-------------------------\n",
      "['antibody', 'antibodies', 'vaccines', 'cell', 'vaccine']\n",
      "-------------------------\n",
      "['avian', 'global', 'h7n9', 'h1n1', 'markets']\n",
      "-------------------------\n",
      "['model', 'west', 'africa', 'outbreaks', 'preparedness']\n",
      "-------------------------\n",
      "['cats', 'feline', 'calicivirus', 'mycoplasma', 'isolation']\n",
      "-------------------------\n",
      "['bronchitis', 'avian', 'detection', 'recombinant', 'isolated']\n",
      "-------------------------\n",
      "['bats', 'zoonotic', 'pathogens', 'bat', 'potential']\n",
      "-------------------------\n",
      "['data', 'estimation', '2019ncov', 'clinical', 'medicine']\n",
      "-------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(ec.meta_arr)):\n",
    "    print(ec.meta_arr[i]['keywords'])\n",
    "    print('-------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['health', 'virus', 'disease', 'infectious', 'influenza', 'respiratory', 'infection', 'coronavirus', 'transmission', 'public', 'pandemic', 'outbreak', 'china', 'diseases', 'novel', 'epidemic', 'ebola', 'covid-19', 'sars', 'analysis']\n"
     ]
    }
   ],
   "source": [
    "print(ec.top_title_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
